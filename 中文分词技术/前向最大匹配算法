import re
from string import punctuation
    
# 定义要删除的标点等字符
add_punc='，。、【 】 “”：；（）《》‘’{}？！⑦()、%^>℃：.”“^-——=&#@￥'
all_punc=punctuation+add_punc

#前向最大匹配
class IMM(object):
    def __init__(self, dic_path,stop_words_dic_path):
        """
        Parameters
        ----------
        dic_path : 存放字典位置
        -------
        将字典文件中的词读入dictionary.

        """
        self.dictionary = set()
        self.stop_words_dic = set()
        self.maximum = 0
        #读取词典
        with open(dic_path, 'r', encoding='utf8') as f:
            for line in f:
                line = line.strip()
                #跳出本次循环，避免空行进入字典
                if not line:
                    continue
                self.dictionary.add(line)
                if len(line) > self.maximum:
                    self.maximum = len(line)
        #读取停用词词典
        with open(stop_words_dic_path, 'r', encoding='utf8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                self.stop_words_dic.add(line)
                    
    def clean(self,text):
        text_clean=''
        for i in text:
            #移除英文和数字
            i_clean=re.sub(r'[A-Za-z0-9]|/d+','',i)
            #移除标点符号
            if i_clean in all_punc:
                i_clean=''
            if len(i_clean)>0:
                text_clean=text_clean+i_clean       
        return text_clean
    
    def cut(self, text):
        #从此位置查询maximum个字
        index=0
        result=[]
        while index<len(text):
            word=None
            for size in range(index+self.maximum,index,-1):
                piece=text[index:size]
                if piece in self.stop_words_dic:
                    word=''
                    break
                if piece in self.dictionary:
                    word=piece
                    result.append(piece)
                    break
            #如果词在字典中不存在
            if word is None:
                index+=1
            #词在字典中存在，指针往后挪词长度以后
            else:
                index=size
        return result

def main():
    text = "算法f南京市1长江?.大桥"
    tokenizer = IMM('./data/imm_dic.utf8','./data/stop_words.utf8')
    text_clean=tokenizer.clean(text)
    print(tokenizer.cut(text_clean))

main()
